---
title: "p8105_hw6_jt3649"
author: "Juan Tang"
date: "2025-11-28"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(modelr)

```

### Problem 1
#### Clean data
```{r clean homicides data}
homicides_raw = read.csv("homicide-data.csv") |>
  janitor::clean_names()
homicides_clean = homicides_raw |>
  mutate(
    city_state = str_c(city, ", ", state), 
    # solved = 1 if closed by arrest, 0 otherwise
    solved = if_else(disposition == "Closed by arrest", 1L, 0L), 
    # suppress non-numeric victim age to NA
    victim_age = suppressWarnings(as.numeric(victim_age))
  ) |>
  # drop cities that do not report victim race or have mistakes
  filter(
    !city_state %in% c(
      "Dallas, TX", 
      "Phoenix, AZ", 
      "Kansas City, MO", 
      "Tulsa, AL"
    )) |>
      # keep only white/black victims
      filter(victim_race %in% c("White", "Black")) |>
      #drop cases with missing variables
      filter(
        !is.na(victim_age), 
        !is.na(victim_sex), 
        !is.na(victim_race)
      )
```
#### Logistic regression for Baltimore, MD
```{r logistic regression for Baltimore, MD}
# outcome: solved
# predictors: victim_age, victim_sex, victim_race
baltimore_data = homicides_clean |>
  filter(city_state == "Baltimore, MD")
# fit logistic regression model
baltimore_fit = glm(
  solved ~ victim_age + victim_sex + victim_race, 
  data = baltimore_data, 
  family = binomial
)
# odds ratio and CI
baltimore_or = baltimore_fit|>
  broom::tidy(exponentiate = TRUE, conf.int = TRUE)
knitr::kable(baltimore_or)
```

#### Odds ratio for male vs female victims in Baltimore, MD
```{r adjusted odds ratio in Baltimore, MD}
baltimore_male_or = baltimore_or |>
  # odds ratio for male to female victims, with other variables constant 
  filter(term == "victim_sexMale") |>
  select(term, estimate, conf.low, conf.high)
knitr::kable(baltimore_male_or)
```

#### Logistic regression for all cities
```{r logistic regression all cities}
city_model = homicides_clean |>
  group_by(city_state) |>
  nest() |>
  mutate(
    # fit glm in each city
    fit = purrr::map(
      data, 
      ~ glm(
        solved ~ victim_age + victim_sex + victim_race, 
        data = .x, 
        family = binomial
      )
    ), 
    # tidy the output
    tidy_fit = purrr::map(
      fit, 
      ~ broom::tidy(
        .x, 
        exponentiate = TRUE, conf.int = TRUE
      )
    )
  ) |>
  select(city_state, tidy_fit) |>
  unnest(tidy_fit)

# keep only male vs female effect with other variables fixed
city_or_male = city_model |>
  filter(term == "victim_sexMale") |>
  select(
    city_state, 
    estimate, 
    conf.low, 
    conf.high
  ) |>
  rename(
    or_male_vs_female = estimate, 
    ci_low = conf.low, 
    ci_high = conf.high
  ) |>
  arrange(or_male_vs_female)

knitr::kable(city_or_male)
```

#### Estimated ORs and CIs plot
```{r OR and CI plot}
ggplot(
  city_or_male, 
  aes(
    x = or_male_vs_female, 
    y = fct_reorder(city_state, or_male_vs_female)
  )
) + 
  geom_point() + 
  geom_errorbarh(
    aes(
      xmin = ci_low, 
      xmax = ci_high
    ), 
    height = 0
  ) + 
  geom_vline(
    xintercept = 1, 
    linetype = "dashed"
  ) + 
  labs(
    title = "Adjusted odds of solving homicides for male vs female victims", 
    x = "Adjusted odds ratio (male vs female)", 
    y = "City"
  ) + 
  theme_minimal(base_size = 12)
```

#### Comments
In most cities, the estimated odds ratio for male versus female victims is smaller than 1, suggesting that homicides with male victims tend to be less likely to be solved than those with female victims, with fixed victim age and race. 

A few cities such as Albuquerque, NM and Stockton, CA have adjusted odds ratios near or above 1, but their confidence intervals are wide. This implies that there could have substantial uncertainties probably due to smaller sample sizes. 

Overall, the plot suggests a consistent pattern where male-victim homicides are less likely to have a resolution, though the strength of this pattern varies by city.

### Problem 2
```{r import dataset}
library(p8105.datasets)
data("weather_df")
set.seed(1234)
# keep only rows with complete data
weather = weather_df |>
  drop_na(tmax, tmin, prcp)
```

#### Bootstrap resamples and estimates
```{r bootstrap estimates}
weather_boot = weather |>
  modelr::bootstrap(n = 5000)
# fit the regression in each bootstrap sample
# extract r^2 and beta1/beta2
boot_result = weather_boot |>
  mutate(
    fit = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)), 
    model_summary = map(fit, broom::glance), 
    coefficients = map(fit, broom::tidy)
  ) |>
  select(-strap, -fit) |>
  unnest(model_summary) |>
  select(
    bootstrap_id = .id, 
    r_sq = r.squared, 
    coefficients
  ) |>
  unnest(coefficients) |>
  filter(term %in% c("tmin", "prcp")) |>
  select(
    bootstrap_id, r_sq, term, coefficient = estimate
  ) |>
  pivot_wider(
    names_from = term, 
    values_from = coefficient
  ) |>
  mutate(beta_ratio = tmin/prcp) |>
  select(bootstrap_id, r_sq, beta_ratio)

boot_result |> head() |>
  knitr::kable()
```

#### Distribution of estimates
```{r distribution plot}
# distribution of r^2
boot_result |>
  ggplot(aes(x = r_sq)) + 
  geom_histogram(bins = 30) + 
  labs(
    title = "Bootstrap distribution of R-squared", 
    x = expression (R^2), 
    y = "Count"
  )

# distribution of beta1/beta2
boot_result |>
  ggplot(aes(x = beta_ratio)) + 
  geom_histogram(bins = 30) + 
  labs(
    title = "Bootstrap distribution of" ~ hat(beta)[1]/hat(beta)[2], 
    x = expression(hat(beta)[1]/hat(beta)[2]), 
    y = "Count"
  )
```

#### 95% Confidence intervals
```{r bootstrap CI}
ci_result = boot_result |>
  summarize(
    r2_lower = quantile(r_sq, 0.025), 
    r2_upper = quantile(r_sq, 0.975), 
    ratio_lower = quantile(beta_ratio, 0.025, na.rm = TRUE), 
    ratio_upper = quantile(beta_ratio, 0.975, na.rm = TRUE)
  )
knitr::kable(ci_result)
```

#### Comment on distribution
##### Distribution of R^2
The bootstrap distribution of r^2 is approximately bell-shaped and symmetric, centered around 0.94. This indicates that across the repeated resampling of the Central Park weather data, the fitted linear regression model with predictors tmin and prcp are able to explain about 94% of the variability in tmax.

The 95% confidence interval for r^2 is [`r round(ci_result[,"r2_lower"], 3)`, `r round(ci_result[,"r2_upper"], 3)`].

##### Distribution of beta1/beta2
The distribution of the coefficient ratio beta1/beta2 is skewed to the left. It shows a much wide spread than the r^2 distribution. This implies that beta1 (coefficient for tmin) is positive and fairly stable, while beta2 (coefficient for prcp) is very close to zero, slightly positive or negative in bootstrap samples.

The 95% confidence interval for r^2 is [`r round(ci_result[,"ratio_lower"], 3)`, `r round(ci_result[,"ratio_upper"], 3)`]. Since the interval does not include zero, beta1 and beta2 tend to have opposite signs in almost all bootstrap samples.

### Problem 3
```{r import birthweight dataset}
birthweight = read_csv("birthweight.csv") |>
  janitor::clean_names()
birthweight_df = birthweight |>
  # convert numeric indicators to factors
  mutate(
   babysex = factor(babysex, levels = c(1,2), labels = c("male", "female")), 
   malform = factor(malform, levels = c(0, 1), labels = c("absent", "present")), 
   frace = factor(
     frace, 
     levels = c(1, 2, 3, 4, 8, 9), 
     labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")
                  ), 
   mrace = factor(
     mrace, 
     levels = c(1, 2, 3, 4, 8), 
     labels = c("White", "Black", "Asian", "Puerto Rican", "Other")
     )
  )

# drop rows with missing data
birthweight_df = birthweight_df |>
  drop_na()
```

#### Proposed regression model
```{r proposed model}
# outcome = bwt
# predictors: baby sex, head circumference, length, gestational age, pre-pregnancy, BMI, smoking, weight gain
bw_model = lm(
  bwt ~ babysex + bhead + blength + gaweeks + ppbmi + smoken + wtgain, 
  data = birthweight_df
)

bw_model_result = bw_model |> broom::tidy()
knitr::kable(bw_model_result)
```

#### Residuals vs fitted plot
```{r residuals vs fitted plot}
birthweight_resid_df = 
  birthweight_df |>
  modelr::add_predictions(bw_model) |>
  modelr::add_residuals(bw_model)

birthweight_resid_df |>
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.3) + 
  geom_hline(yintercept = 0, linetype = "dashed") + 
  labs(
    x = "Fitted values", 
    y = "Residuals", 
    title = "Residuals vs fitted values for birthweight model"
  )
```

#### Main effect model and interaction model
```{r main effect model}
bw_len_gae_model = 
  lm(
    bwt ~ blength + gaweeks, 
     data = birthweight_df
    )

bw_head_len_sex_int_model = 
  lm(
    bwt ~ bhead * blength * babysex, 
    data = birthweight_df
  )
```

#### Cross validation
```{r cross validation}
cv_df = 
  crossv_mc(birthweight_df, 100) |>
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble)
  ) |>
  mutate(
    # fit each model on each training set
    # proposed bw model
    bw_prop_model = map(
      train, 
      \(df) lm(
        bwt ~ babysex + bhead + blength + gaweeks + ppbmi + smoken + wtgain, 
        data = df
      )
    ), 
    # main effect model
    bw_len_gae_model = map(
      train, 
      \(df) lm(bwt ~ blength + gaweeks, data = df)
    ), 
    # interaction model
    bw_head_len_sex_int_model = map(
      train, 
      \(df) lm(bwt ~ bhead * blength * babysex, data = df)
    )
  ) |>
  mutate(
    # compute RMSE on corresponding test set
    rmse_prop = map2_dbl(bw_prop_model, test, \(mod, df) rmse(model = mod, data = df)), 
    rmse_len_gae = map2_dbl(bw_len_gae_model, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_head_len_sex_int_model = map2_dbl(bw_head_len_sex_int_model, test, \(mod, df) rmse(model = mod, data = df))
  )

cv_df |>
  select(starts_with("rmse")) |>
  summary()
```

#### Plot and compare cross validation RMSEs
```{r compare cv}
cv_long = 
  cv_df |>
  select(starts_with("rmse")) |>
  pivot_longer(
    cols = everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_"
  ) |>
  mutate(model = fct_inorder(model))

cv_summary = cv_long |>
  group_by(model) |>
  summarize(
    mean_rmse = mean(rmse), 
    sd_rmse = sd(rmse)
  ) |>
  knitr::kable()

cv_long |>
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() + 
  geom_boxplot(width = 0.15, outlier.alpha = 0.3) + 
  labs(
    x = "Model", 
    y = "RMSE (cross-validated)", 
    title = "Comparison of cross-validated prediction error"
  )

```

