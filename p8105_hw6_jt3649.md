p8105_hw6_jt3649
================
Juan Tang
2025-11-28

### Problem 1

#### Clean data

``` r
homicides_raw = read.csv("homicide-data.csv") |>
  janitor::clean_names()
homicides_clean = homicides_raw |>
  mutate(
    city_state = str_c(city, ", ", state), 
    # solved = 1 if closed by arrest, 0 otherwise
    solved = if_else(disposition == "Closed by arrest", 1L, 0L), 
    # suppress non-numeric victim age to NA
    victim_age = suppressWarnings(as.numeric(victim_age))
  ) |>
  # drop cities that do not report victim race or have mistakes
  filter(
    !city_state %in% c(
      "Dallas, TX", 
      "Phoenix, AZ", 
      "Kansas City, MO", 
      "Tulsa, AL"
    )) |>
      # keep only white/black victims
      filter(victim_race %in% c("White", "Black")) |>
      #drop cases with missing variables
      filter(
        !is.na(victim_age), 
        !is.na(victim_sex), 
        !is.na(victim_race)
      )
```

#### Logistic regression for Baltimore, MD

``` r
# outcome: solved
# predictors: victim_age, victim_sex, victim_race
baltimore_data = homicides_clean |>
  filter(city_state == "Baltimore, MD")
# fit logistic regression model
baltimore_fit = glm(
  solved ~ victim_age + victim_sex + victim_race, 
  data = baltimore_data, 
  family = binomial
)
# odds ratio and CI
baltimore_or = baltimore_fit|>
  broom::tidy(exponentiate = TRUE, conf.int = TRUE)
knitr::kable(baltimore_or)
```

| term             |  estimate | std.error | statistic |   p.value |  conf.low | conf.high |
|:-----------------|----------:|----------:|----------:|----------:|----------:|----------:|
| (Intercept)      | 1.3633992 | 0.1712948 |  1.809635 | 0.0703525 | 0.9757573 | 1.9107826 |
| victim_age       | 0.9932953 | 0.0033235 | -2.024124 | 0.0429574 | 0.9868059 | 0.9997539 |
| victim_sexMale   | 0.4255117 | 0.1381762 | -6.183864 | 0.0000000 | 0.3241908 | 0.5575508 |
| victim_raceWhite | 2.3204389 | 0.1747162 |  4.817851 | 0.0000015 | 1.6496269 | 3.2759334 |

#### Odds ratio for male vs female victims in Baltimore, MD

``` r
baltimore_male_or = baltimore_or |>
  # odds ratio for male to female victims, with other variables constant 
  filter(term == "victim_sexMale") |>
  select(term, estimate, conf.low, conf.high)
knitr::kable(baltimore_male_or)
```

| term           |  estimate |  conf.low | conf.high |
|:---------------|----------:|----------:|----------:|
| victim_sexMale | 0.4255117 | 0.3241908 | 0.5575508 |

#### Logistic regression for all cities

``` r
city_model = homicides_clean |>
  group_by(city_state) |>
  nest() |>
  mutate(
    # fit glm in each city
    fit = purrr::map(
      data, 
      ~ glm(
        solved ~ victim_age + victim_sex + victim_race, 
        data = .x, 
        family = binomial
      )
    ), 
    # tidy the output
    tidy_fit = purrr::map(
      fit, 
      ~ broom::tidy(
        .x, 
        exponentiate = TRUE, conf.int = TRUE
      )
    )
  ) |>
  select(city_state, tidy_fit) |>
  unnest(tidy_fit)
```

    ## Warning: There were 43 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `tidy_fit = purrr::map(fit, ~broom::tidy(.x, exponentiate =
    ##   TRUE, conf.int = TRUE))`.
    ## ℹ In group 1: `city_state = "Albuquerque, NM"`.
    ## Caused by warning:
    ## ! glm.fit: fitted probabilities numerically 0 or 1 occurred
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 42 remaining warnings.

``` r
# keep only male vs female effect with other variables fixed
city_or_male = city_model |>
  filter(term == "victim_sexMale") |>
  select(
    city_state, 
    estimate, 
    conf.low, 
    conf.high
  ) |>
  rename(
    or_male_vs_female = estimate, 
    ci_low = conf.low, 
    ci_high = conf.high
  ) |>
  arrange(or_male_vs_female)

knitr::kable(city_or_male)
```

| city_state         | or_male_vs_female |    ci_low |   ci_high |
|:-------------------|------------------:|----------:|----------:|
| New York, NY       |         0.2623978 | 0.1327512 | 0.4850117 |
| Baton Rouge, LA    |         0.3814393 | 0.2043481 | 0.6836343 |
| Omaha, NE          |         0.3824861 | 0.1988357 | 0.7109316 |
| Cincinnati, OH     |         0.3998277 | 0.2313767 | 0.6670456 |
| Chicago, IL        |         0.4100982 | 0.3361233 | 0.5008546 |
| Long Beach, CA     |         0.4102163 | 0.1427304 | 1.0241775 |
| San Diego, CA      |         0.4130248 | 0.1913527 | 0.8301847 |
| Baltimore, MD      |         0.4255117 | 0.3241908 | 0.5575508 |
| Pittsburgh, PA     |         0.4307528 | 0.2626022 | 0.6955518 |
| Denver, CO         |         0.4790620 | 0.2327380 | 0.9624974 |
| Louisville, KY     |         0.4905546 | 0.3014879 | 0.7836391 |
| Philadelphia, PA   |         0.4962756 | 0.3760120 | 0.6498797 |
| San Bernardino, CA |         0.5003444 | 0.1655367 | 1.4623977 |
| Miami, FL          |         0.5152379 | 0.3040214 | 0.8734480 |
| Buffalo, NY        |         0.5205704 | 0.2884416 | 0.9358300 |
| Columbus, OH       |         0.5324845 | 0.3770457 | 0.7479124 |
| Oakland, CA        |         0.5630819 | 0.3637421 | 0.8671086 |
| Detroit, MI        |         0.5823472 | 0.4619454 | 0.7335458 |
| New Orleans, LA    |         0.5849373 | 0.4218807 | 0.8121787 |
| San Francisco, CA  |         0.6075362 | 0.3116925 | 1.1551470 |
| Los Angeles, CA    |         0.6618816 | 0.4565014 | 0.9541036 |
| Sacramento, CA     |         0.6688418 | 0.3262733 | 1.3143888 |
| Fort Worth, TX     |         0.6689803 | 0.3935128 | 1.1211603 |
| Boston, MA         |         0.6739912 | 0.3534469 | 1.2768225 |
| Washington, DC     |         0.6901713 | 0.4653608 | 1.0122516 |
| St. Louis, MO      |         0.7031665 | 0.5298505 | 0.9319005 |
| San Antonio, TX    |         0.7046200 | 0.3928179 | 1.2382509 |
| Houston, TX        |         0.7110264 | 0.5569844 | 0.9057376 |
| Jacksonville, FL   |         0.7198144 | 0.5359236 | 0.9650986 |
| Memphis, TN        |         0.7232194 | 0.5261210 | 0.9835973 |
| Milwaukee, wI      |         0.7271327 | 0.4951325 | 1.0542297 |
| Tampa, FL          |         0.8077029 | 0.3395253 | 1.8598834 |
| Durham, NC         |         0.8123514 | 0.3824420 | 1.6580169 |
| Las Vegas, NV      |         0.8373078 | 0.6058830 | 1.1510854 |
| Savannah, GA       |         0.8669817 | 0.4185827 | 1.7802453 |
| Birmingham, AL     |         0.8700153 | 0.5713814 | 1.3138409 |
| Charlotte, NC      |         0.8838976 | 0.5507440 | 1.3905954 |
| Indianapolis, IN   |         0.9187284 | 0.6784616 | 1.2413059 |
| Minneapolis, MN    |         0.9469587 | 0.4759016 | 1.8809745 |
| Oklahoma City, OK  |         0.9740747 | 0.6228507 | 1.5199721 |
| Tulsa, OK          |         0.9757694 | 0.6090664 | 1.5439356 |
| Atlanta, GA        |         1.0000771 | 0.6803477 | 1.4582575 |
| Richmond, VA       |         1.0060520 | 0.4834671 | 1.9936248 |
| Nashville, TN      |         1.0342379 | 0.6807452 | 1.5559966 |
| Fresno, CA         |         1.3351647 | 0.5672553 | 3.0475080 |
| Stockton, CA       |         1.3517273 | 0.6256427 | 2.9941299 |
| Albuquerque, NM    |         1.7674995 | 0.8247081 | 3.7618600 |

#### Estimated ORs and CIs plot

``` r
ggplot(
  city_or_male, 
  aes(
    x = or_male_vs_female, 
    y = fct_reorder(city_state, or_male_vs_female)
  )
) + 
  geom_point() + 
  geom_errorbarh(
    aes(
      xmin = ci_low, 
      xmax = ci_high
    ), 
    height = 0
  ) + 
  geom_vline(
    xintercept = 1, 
    linetype = "dashed"
  ) + 
  labs(
    title = "Adjusted odds of solving homicides for male vs female victims", 
    x = "Adjusted odds ratio (male vs female)", 
    y = "City"
  ) + 
  theme_minimal(base_size = 12)
```

![](p8105_hw6_jt3649_files/figure-gfm/OR%20and%20CI%20plot-1.png)<!-- -->

#### Comments

In most cities, the estimated odds ratio for male versus female victims
is smaller than 1, suggesting that homicides with male victims tend to
be less likely to be solved than those with female victims, with fixed
victim age and race.

A few cities such as Albuquerque, NM and Stockton, CA have adjusted odds
ratios near or above 1, but their confidence intervals are wide. This
implies that there could have substantial uncertainties probably due to
smaller sample sizes.

Overall, the plot suggests a consistent pattern where male-victim
homicides are less likely to have a resolution, though the strength of
this pattern varies by city.

### Problem 2

``` r
library(p8105.datasets)
data("weather_df")
# keep only rows with complete data
weather = weather_df |>
  drop_na(tmax, tmin, prcp)
```

#### Bootstrap resamples and estimates

``` r
set.seed(1234)
weather_boot = weather |>
  modelr::bootstrap(n = 5000)
# fit the regression in each bootstrap sample
# extract r^2 and beta1/beta2
boot_result = weather_boot |>
  mutate(
    fit = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)), 
    model_summary = map(fit, broom::glance), 
    coefficients = map(fit, broom::tidy)
  ) |>
  select(-strap, -fit) |>
  unnest(model_summary) |>
  select(
    bootstrap_id = .id, 
    r_sq = r.squared, 
    coefficients
  ) |>
  unnest(coefficients) |>
  filter(term %in% c("tmin", "prcp")) |>
  select(
    bootstrap_id, r_sq, term, coefficient = estimate
  ) |>
  pivot_wider(
    names_from = term, 
    values_from = coefficient
  ) |>
  mutate(beta_ratio = tmin/prcp) |>
  select(bootstrap_id, r_sq, beta_ratio)

boot_result |> head() |>
  knitr::kable()
```

| bootstrap_id |      r_sq | beta_ratio |
|:-------------|----------:|-----------:|
| 0001         | 0.9441702 |  -134.2074 |
| 0002         | 0.9408147 |  -273.5056 |
| 0003         | 0.9389278 |  -182.1633 |
| 0004         | 0.9294275 |  -194.6805 |
| 0005         | 0.9432072 |  -161.4898 |
| 0006         | 0.9431148 |  -164.1362 |

#### Distribution of estimates

``` r
# distribution of r^2
boot_result |>
  ggplot(aes(x = r_sq)) + 
  geom_histogram(bins = 30) + 
  labs(
    title = "Bootstrap distribution of R-squared", 
    x = expression (R^2), 
    y = "Count"
  )
```

![](p8105_hw6_jt3649_files/figure-gfm/distribution%20plot-1.png)<!-- -->

``` r
# distribution of beta1/beta2
boot_result |>
  ggplot(aes(x = beta_ratio)) + 
  geom_histogram(bins = 30) + 
  labs(
    title = "Bootstrap distribution of" ~ hat(beta)[1]/hat(beta)[2], 
    x = expression(hat(beta)[1]/hat(beta)[2]), 
    y = "Count"
  )
```

![](p8105_hw6_jt3649_files/figure-gfm/distribution%20plot-2.png)<!-- -->

#### 95% Confidence intervals

``` r
ci_result = boot_result |>
  summarize(
    r2_lower = quantile(r_sq, 0.025), 
    r2_upper = quantile(r_sq, 0.975), 
    ratio_lower = quantile(beta_ratio, 0.025, na.rm = TRUE), 
    ratio_upper = quantile(beta_ratio, 0.975, na.rm = TRUE)
  )
knitr::kable(ci_result)
```

|  r2_lower |  r2_upper | ratio_lower | ratio_upper |
|----------:|----------:|------------:|------------:|
| 0.9341438 | 0.9466008 |    -277.696 |   -124.9267 |

#### Comment on distribution

##### Distribution of R^2

The bootstrap distribution of r^2 is approximately bell-shaped and
symmetric, centered around 0.94. This indicates that across the repeated
resampling of the Central Park weather data, the fitted linear
regression model with predictors tmin and prcp are able to explain about
94% of the variability in tmax.

The 95% confidence interval for r^2 is \[0.934, 0.947\].

##### Distribution of beta1/beta2

The distribution of the coefficient ratio beta1/beta2 is skewed to the
left. It shows a much wide spread than the r^2 distribution. This
implies that beta1 (coefficient for tmin) is positive and fairly stable,
while beta2 (coefficient for prcp) is very close to zero, slightly
positive or negative in bootstrap samples.

The 95% confidence interval for r^2 is \[-277.696, -124.927\]. Since the
interval does not include zero, beta1 and beta2 tend to have opposite
signs in almost all bootstrap samples.

### Problem 3

``` r
birthweight = read_csv("birthweight.csv") |>
  janitor::clean_names()
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
birthweight_df = birthweight |>
  # convert numeric indicators to factors
  mutate(
   babysex = factor(babysex, levels = c(1,2), labels = c("male", "female")), 
   malform = factor(malform, levels = c(0, 1), labels = c("absent", "present")), 
   frace = factor(
     frace, 
     levels = c(1, 2, 3, 4, 8, 9), 
     labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")
                  ), 
   mrace = factor(
     mrace, 
     levels = c(1, 2, 3, 4, 8), 
     labels = c("White", "Black", "Asian", "Puerto Rican", "Other")
     )
  )

# drop rows with missing data
birthweight_df = birthweight_df |>
  drop_na()
```

#### Proposed regression model

The proposed model was based on a hypothesized structure for the
biological and maternal factors that underlie birthweight, such as baby
sex, head circumference, etc..

The modeling process involved selecting predictors based on theoretical
expectations about birthweight determinants. The relationship between
predictors and outcome is compared through fitting in a multiple linear
regression model. The model accuracy is accessed through residual
diagnostics. The proposed model is also compared to two other models
using cross-validated prediction error.

``` r
# outcome = bwt
# predictors: baby sex, head circumference, length, gestational age, pre-pregnancy, BMI, smoking, weight gain
bw_model = lm(
  bwt ~ babysex + bhead + blength + gaweeks + ppbmi + smoken + wtgain, 
  data = birthweight_df
)

bw_model_result = bw_model |> broom::tidy()
knitr::kable(bw_model_result)
```

| term          |     estimate |  std.error |  statistic |   p.value |
|:--------------|-------------:|-----------:|-----------:|----------:|
| (Intercept)   | -6205.868398 | 99.7742627 | -62.199090 | 0.0000000 |
| babysexfemale |    32.402515 |  8.7512423 |   3.702619 | 0.0002160 |
| bhead         |   137.612940 |  3.5432606 |  38.837939 | 0.0000000 |
| blength       |    79.529893 |  2.0705253 |  38.410492 | 0.0000000 |
| gaweeks       |    13.509797 |  1.5039813 |   8.982690 | 0.0000000 |
| ppbmi         |     5.125069 |  1.3653639 |   3.753628 | 0.0001766 |
| smoken        |    -1.997660 |  0.5827272 |  -3.428123 | 0.0006134 |
| wtgain        |     3.720352 |  0.4054125 |   9.176709 | 0.0000000 |

#### Residuals vs fitted plot

``` r
birthweight_resid_df = 
  birthweight_df |>
  modelr::add_predictions(bw_model) |>
  modelr::add_residuals(bw_model)

birthweight_resid_df |>
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.3) + 
  geom_hline(yintercept = 0, linetype = "dashed") + 
  labs(
    x = "Fitted values", 
    y = "Residuals", 
    title = "Residuals vs fitted values for birthweight model"
  )
```

![](p8105_hw6_jt3649_files/figure-gfm/residuals%20vs%20fitted%20plot-1.png)<!-- -->

#### Main effect model and interaction model

``` r
bw_len_gae_model = 
  lm(
    bwt ~ blength + gaweeks, 
     data = birthweight_df
    )

bw_head_len_sex_int_model = 
  lm(
    bwt ~ bhead * blength * babysex, 
    data = birthweight_df
  )
```

#### Cross validation

``` r
set.seed(1234)
cv_df = 
  crossv_mc(birthweight_df, 100) |>
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble)
  ) |>
  mutate(
    # fit each model on each training set
    # proposed bw model
    bw_prop_model = map(
      train, 
      \(df) lm(
        bwt ~ babysex + bhead + blength + gaweeks + ppbmi + smoken + wtgain, 
        data = df
      )
    ), 
    # main effect model
    bw_len_gae_model = map(
      train, 
      \(df) lm(bwt ~ blength + gaweeks, data = df)
    ), 
    # interaction model
    bw_head_len_sex_int_model = map(
      train, 
      \(df) lm(bwt ~ bhead * blength * babysex, data = df)
    )
  ) |>
  mutate(
    # compute RMSE on corresponding test set
    rmse_prop = map2_dbl(bw_prop_model, test, \(mod, df) rmse(model = mod, data = df)), 
    rmse_len_gae = map2_dbl(bw_len_gae_model, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_head_len_sex_int_model = map2_dbl(bw_head_len_sex_int_model, test, \(mod, df) rmse(model = mod, data = df))
  )

cv_df |>
  select(starts_with("rmse")) |>
  summary()
```

    ##    rmse_prop      rmse_len_gae   rmse_head_len_sex_int_model
    ##  Min.   :261.1   Min.   :306.7   Min.   :267.9              
    ##  1st Qu.:276.0   1st Qu.:323.4   1st Qu.:280.6              
    ##  Median :281.2   Median :330.3   Median :286.7              
    ##  Mean   :283.4   Mean   :335.5   Mean   :289.7              
    ##  3rd Qu.:291.2   3rd Qu.:349.8   3rd Qu.:297.0              
    ##  Max.   :310.4   Max.   :376.2   Max.   :318.2

#### Plot and compare cross validation RMSEs

``` r
cv_long = 
  cv_df |>
  select(starts_with("rmse")) |>
  pivot_longer(
    cols = everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_"
  ) |>
  mutate(model = fct_inorder(model))

cv_summary = cv_long |>
  group_by(model) |>
  summarize(
    mean_rmse = mean(rmse), 
    sd_rmse = sd(rmse),
    median_rmse = median(rmse)
  )

knitr::kable(cv_summary)
```

| model                  | mean_rmse |  sd_rmse | median_rmse |
|:-----------------------|----------:|---------:|------------:|
| prop                   |  283.4432 | 10.83544 |    281.2097 |
| len_gae                |  335.4731 | 16.98099 |    330.3114 |
| head_len_sex_int_model |  289.6828 | 11.69083 |    286.7302 |

``` r
cv_long |>
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() + 
  geom_boxplot(width = 0.15, outlier.alpha = 0.3) + 
  labs(
    x = "Model", 
    y = "RMSE (cross-validated)", 
    title = "Comparison of cross-validated prediction error"
  )
```

![](p8105_hw6_jt3649_files/figure-gfm/compare%20cv-1.png)<!-- -->

The violin plots shows that the proposed model has the smallest mean
RMSE (283.443) and median RMSE (281.21). The entire distribution is
shifted downward relative to the two other models (main effect model and
interaction model). The small RMSE indicates better predictive accuracy
of the proposed model. Among the three, the main effect (len + gae)
model has the highest mean and median RMSE, and the entire distribution
is higher. This implies worse performance on predicting birthweight
outcome.
